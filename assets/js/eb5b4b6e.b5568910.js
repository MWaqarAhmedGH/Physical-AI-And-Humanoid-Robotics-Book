"use strict";(self.webpackChunkphysical_ai_and_humanoid_robotics=self.webpackChunkphysical_ai_and_humanoid_robotics||[]).push([[3446],{4606:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-4-vla/exercises","title":"Tasks: Module 4 \u2014 Vision-Language-Action (VLA)","description":"Input: Design documents from specs/004-vla-module/","source":"@site/docs/module-4-vla/exercises.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/exercises","permalink":"/Physical-AI-And-Humanoid-Robotics/docs/module-4-vla/exercises","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4-vla/exercises.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Quickstart: Contributing to the VLA Module","permalink":"/Physical-AI-And-Humanoid-Robotics/docs/module-4-vla/quickstart"}}');var t=n(4848),o=n(8453);const r={},a="Tasks: Module 4 \u2014 Vision-Language-Action (VLA)",l={},c=[{value:"Format: <code>[ID] [P?] [Story] Description</code>",id:"format-id-p-story-description",level:2},{value:"Path Conventions",id:"path-conventions",level:2},{value:"Phase 1: Setup (Shared Infrastructure)",id:"phase-1-setup-shared-infrastructure",level:2},{value:"Phase 2: Foundational (Blocking Prerequisites)",id:"phase-2-foundational-blocking-prerequisites",level:2},{value:"Phase 3: User Story 1 - Voice Command a Robot (Priority: P1) \ud83c\udfaf MVP",id:"phase-3-user-story-1---voice-command-a-robot-priority-p1--mvp",level:2},{value:"Implementation for User Story 1",id:"implementation-for-user-story-1",level:3},{value:"Phase 4: User Story 2 - LLM-driven Robotic Planning (Priority: P2)",id:"phase-4-user-story-2---llm-driven-robotic-planning-priority-p2",level:2},{value:"Implementation for User Story 2",id:"implementation-for-user-story-2",level:3},{value:"Phase 5: User Story 3 - Build an End-to-End VLA System (Priority: P3)",id:"phase-5-user-story-3---build-an-end-to-end-vla-system-priority-p3",level:2},{value:"Implementation for User Story 3",id:"implementation-for-user-story-3",level:3},{value:"Phase 6: Polish &amp; Cross-Cutting Concerns",id:"phase-6-polish--cross-cutting-concerns",level:2},{value:"Dependencies &amp; Execution Order",id:"dependencies--execution-order",level:2}];function d(e){const s={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",input:"input",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.header,{children:(0,t.jsx)(s.h1,{id:"tasks-module-4--vision-language-action-vla",children:"Tasks: Module 4 \u2014 Vision-Language-Action (VLA)"})}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Input"}),": Design documents from ",(0,t.jsx)(s.code,{children:"specs/004-vla-module/"}),"\n",(0,t.jsx)(s.strong,{children:"Prerequisites"}),": plan.md, spec.md"]}),"\n",(0,t.jsxs)(s.h2,{id:"format-id-p-story-description",children:["Format: ",(0,t.jsx)(s.code,{children:"[ID] [P?] [Story] Description"})]}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"[P]"}),": Can run in parallel"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"[Story]"}),": Which user story this task belongs to (e.g., US1, US2, US3)"]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"path-conventions",children:"Path Conventions"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:"Paths shown below assume documentation project structure from plan.md"}),"\n"]}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h2,{id:"phase-1-setup-shared-infrastructure",children:"Phase 1: Setup (Shared Infrastructure)"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Purpose"}),": Project initialization and basic structure"]}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",checked:!0,disabled:!0})," ","T001 Create the directory structure for the VLA module in ",(0,t.jsx)(s.code,{children:"docs/vla-module"}),"."]}),"\n"]}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h2,{id:"phase-2-foundational-blocking-prerequisites",children:"Phase 2: Foundational (Blocking Prerequisites)"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Purpose"}),": Core infrastructure that MUST be complete before ANY user story can be implemented"]}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",checked:!0,disabled:!0})," ","T002 Add the VLA module to the Docusaurus sidebar in ",(0,t.jsx)(s.code,{children:"docusaurus.config.js"}),"."]}),"\n"]}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h2,{id:"phase-3-user-story-1---voice-command-a-robot-priority-p1--mvp",children:"Phase 3: User Story 1 - Voice Command a Robot (Priority: P1) \ud83c\udfaf MVP"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Goal"}),": Readers can understand how to use voice commands to control a robot."]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Independent Test"}),': The reader can successfully issue a voice command (e.g., "move forward") and observe the robot performing the corresponding action in a simulation.']}),"\n",(0,t.jsx)(s.h3,{id:"implementation-for-user-story-1",children:"Implementation for User Story 1"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",checked:!0,disabled:!0})," ","T003 [P] [US1] Write Chapter 1: Introduction to VLA Systems in ",(0,t.jsx)(s.code,{children:"docs/vla-module/01-introduction.md"}),"."]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",checked:!0,disabled:!0})," ","T004 [P] [US1] Write Chapter 2: Voice-to-Action: Using OpenAI Whisper for Command Recognition in ",(0,t.jsx)(s.code,{children:"docs/vla-module/02-voice-to-action.md"}),"."]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",checked:!0,disabled:!0})," ","T005 [US1] Create a simple Python script to demonstrate OpenAI Whisper for voice recognition in ",(0,t.jsx)(s.code,{children:"examples/vla/"}),"."]}),"\n"]}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h2,{id:"phase-4-user-story-2---llm-driven-robotic-planning-priority-p2",children:"Phase 4: User Story 2 - LLM-driven Robotic Planning (Priority: P2)"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Goal"}),": Readers can use LLMs to translate high-level commands into robot actions."]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Independent Test"}),': The reader can provide a high-level command (e.g., "pick up the red block") to an LLM, and observe it generating a valid sequence of ROS 2 actions to achieve that goal.']}),"\n",(0,t.jsx)(s.h3,{id:"implementation-for-user-story-2",children:"Implementation for User Story 2"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",checked:!0,disabled:!0})," ","T006 [P] [US2] Write Chapter 3: Cognitive Planning with LLMs: Translating Language into ROS 2 Action Plans in ",(0,t.jsx)(s.code,{children:"docs/vla-module/03-cognitive-planning-with-llms.md"}),"."]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",checked:!0,disabled:!0})," ","T007 [US2] Create a Python script demonstrating an LLM generating ROS 2 action plans from natural language in ",(0,t.jsx)(s.code,{children:"examples/vla/"}),"."]}),"\n"]}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h2,{id:"phase-5-user-story-3---build-an-end-to-end-vla-system-priority-p3",children:"Phase 5: User Story 3 - Build an End-to-End VLA System (Priority: P3)"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Goal"}),": Readers can build an end-to-end VLA system for a humanoid robot."]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Independent Test"}),": The reader can integrate all components (voice, LLM, vision, ROS 2 actions) to enable a humanoid robot to execute a specified task autonomously based on a natural language command."]}),"\n",(0,t.jsx)(s.h3,{id:"implementation-for-user-story-3",children:"Implementation for User Story 3"}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",checked:!0,disabled:!0})," ","T008 [P] [US3] Write Chapter 4: Visual Perception for Object Understanding in Humanoids in ",(0,t.jsx)(s.code,{children:"docs/vla-module/04-visual-perception.md"}),"."]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",checked:!0,disabled:!0})," ","T009 [P] [US3] Write Chapter 5: Integrating Vision, Language, and Action into a Unified Pipeline in ",(0,t.jsx)(s.code,{children:"docs/vla-module/05-integrating-vla.md"}),"."]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",checked:!0,disabled:!0})," ","T010 [P] [US3] Write Chapter 6: Capstone: Building the Autonomous Humanoid (End-to-End Task Execution) in ",(0,t.jsx)(s.code,{children:"docs/vla-module/06-capstone-autonomous-humanoid.md"}),"."]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",checked:!0,disabled:!0})," ","T011 [US3] Develop a simple end-to-end VLA system combining voice, LLM, vision, and ROS 2 actions in simulation in ",(0,t.jsx)(s.code,{children:"examples/vla/"}),"."]}),"\n"]}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h2,{id:"phase-6-polish--cross-cutting-concerns",children:"Phase 6: Polish & Cross-Cutting Concerns"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Purpose"}),": Improvements that affect multiple user stories"]}),"\n",(0,t.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",checked:!0,disabled:!0})," ","T012 Write Chapter 7: Chapter Review + Evaluation Tasks in ",(0,t.jsx)(s.code,{children:"docs/vla-module/07-review-evaluation.md"}),"."]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",checked:!0,disabled:!0})," ","T013 Review all chapters for clarity, consistency, and technical accuracy."]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",checked:!0,disabled:!0})," ","T014 Test all code examples and simulations."]}),"\n",(0,t.jsxs)(s.li,{className:"task-list-item",children:[(0,t.jsx)(s.input,{type:"checkbox",checked:!0,disabled:!0})," ","T015 Update the main ",(0,t.jsx)(s.code,{children:"docs/index.md"})," to link to the new module."]}),"\n"]}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h2,{id:"dependencies--execution-order",children:"Dependencies & Execution Order"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Setup (Phase 1)"})," and ",(0,t.jsx)(s.strong,{children:"Foundational (Phase 2)"})," must be completed before any user story work begins."]}),"\n",(0,t.jsx)(s.li,{children:"User stories can be implemented in parallel after Phase 2 is complete."}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Polish (Phase 6)"})," depends on all user stories being complete."]}),"\n"]})]})}function h(e={}){const{wrapper:s}={...(0,o.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,s,n)=>{n.d(s,{R:()=>r,x:()=>a});var i=n(6540);const t={},o=i.createContext(t);function r(e){const s=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function a(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),i.createElement(o.Provider,{value:s},e.children)}}}]);